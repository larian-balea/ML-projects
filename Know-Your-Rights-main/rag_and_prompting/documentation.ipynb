{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4f2543",
   "metadata": {},
   "source": [
    "## Model Selection Summary for Legal RAG Application (Romanian)\n",
    "\n",
    "### Goal\n",
    "\n",
    "We are building a Retrieval-Augmented Generation (RAG) application that answers legal questions using Romanian legal texts like the Constitution and laws. The answers must be in Romanian, and the model has to run locally.\n",
    "\n",
    "### Research Process\n",
    "\n",
    "1. **Language support**\n",
    "   We looked for models that understand and generate Romanian well. Legal texts require precise language, so this was a key point.\n",
    "\n",
    "2. **Size and efficiency**\n",
    "   We needed models that are small enough to run on local machines, ideally in quantized format (like Q4), and compatible with LM Studio.\n",
    "\n",
    "3. **Model availability**\n",
    "   To make things easier, we focused on models available on Hugging Face, especially those that can be downloaded in GGUF format.\n",
    "\n",
    "### Models Chosen\n",
    "\n",
    "We decided to test three models:\n",
    "\n",
    "1. **RoLlama2-7b-Instruct-GGUF (Q4)**\n",
    "   A Romanian language model based on LLaMA 2. It's small, trained on Romanian data, and works well on local hardware.\n",
    "\n",
    "2. **NikolayKozloff/RoLlama3-8b-Instruct-Q4\\_0-GGUF**\n",
    "   Based on LLaMA 3, this model is also focused on Romanian and has better performance. It's available in a quantized format for local use.\n",
    "\n",
    "3. **Mistral-7B-Instruct (multilingual)**\n",
    "   A general-purpose model trained on many languages. It wasn’t trained specifically on Romanian, but we included it to compare how a multilingual model performs against Romanian-only models.\n",
    "\n",
    "### Why These Models?\n",
    "\n",
    "These three models give us a good balance:\n",
    "\n",
    "* Two models specialized in Romanian, including legal use.\n",
    "* One multilingual model to compare performance.\n",
    "* All are available on Hugging Face and compatible with LM Studio.\n",
    "* All can run locally in quantized format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b5374",
   "metadata": {},
   "source": [
    "### **Summary of Romanian Prompt Testing for Three Models**\n",
    "\n",
    "I tested three language models — **Rollama3-8b**, **Rollama2-7b**, and **Mistral** — on six legal questions in Romanian. Each model’s responses were evaluated based on four key aspects: **relevance** (if the answer matches the question), **recall** (if it uses the correct information), **faithfulness** (if it’s factually accurate), and **understanding** (if it’s easy to read).\n",
    "\n",
    "#### ✅ Rollama3-8b\n",
    "\n",
    "* This model had the **best results overall**.\n",
    "* **4 out of 6 answers** passed at least two evaluation tests.\n",
    "* The answers were **grammatically correct** and mostly accurate.\n",
    "* However, some responses were **too long and complicated**, which made them harder to understand.\n",
    "\n",
    "#### ⚠️ Rollama2-7b\n",
    "\n",
    "* Performance was **average**.\n",
    "* It gave **3 strong answers** out of 6.\n",
    "* The language was sometimes **easier to read** than Rollama3, but there were **grammar mistakes** and **some incorrect or missing legal facts**.\n",
    "* Still, it could be a decent alternative depending on the use case.\n",
    "\n",
    "#### ❌ Mistral\n",
    "\n",
    "* This model had the **worst performance**.\n",
    "* Although **4 answers passed** two tests, **one answer failed all tests**.\n",
    "* The grammar was **poor**, and many sentences were **confusing or incorrect**.\n",
    "* The output often included **nonsense words**, **contradictions**, or **legal errors**.\n",
    "\n",
    "I **expected Mistral to perform poorly** since it wasn’t trained on Romanian data. Because of this and its low quality, I’ve decided to **drop Mistral** from my testing process. This will also help make the prompt testing process **faster and more focused**.\n",
    "```\n",
    "prompt = \"\"\"\n",
    "Ești un asistent juridic virtual, specializat în explicarea drepturilor cetățenilor într-un limbaj simplu și accesibil. Răspunzi în limba română, folosind informațiile din documente juridice oficiale precum Constituția României, Codul Muncii sau alte acte normative relevante.\n",
    "\n",
    "Când răspunzi, urmează aceste reguli:\n",
    " - Explică termenii juridici într-un mod clar, ca și cum ai vorbi cu cineva fără pregătire juridică.\n",
    " - Fii concis, dar oferă informații corecte și complete.\n",
    " - Dacă este cazul, poți cita articole de lege (ex: „Conform articolului X din Codul Muncii...”).\n",
    " - Nu inventa informații. Dacă întrebarea nu are un răspuns clar în documentele juridice disponibile, spune că nu poți oferi un răspuns sigur.\n",
    " - Nu oferi sfaturi legale personalizate; explică doar cadrul legal general.\n",
    "\n",
    "Întrebarea utilizatorului este: {question}\n",
    "\n",
    "Folosește următoarele informații extrase din documentele juridice:\n",
    "{context}\n",
    "\n",
    "Răspunsul tău trebuie să fie în limba română, clar, politicos și ușor de înțeles.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a99d6",
   "metadata": {},
   "source": [
    "### **Summary of Prompt Changes and Their Purpose**\n",
    "\n",
    "You updated your prompt to improve the quality and reliability of answers in Romanian, especially when testing models like Rollama and Mistral. Below are the main changes you made and why:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Changed role from “asistent juridic” to “ghid juridic”**\n",
    "\n",
    "* **Before**: “Ești un asistent juridic virtual...”\n",
    "* **Now**: “Ești un ghid juridic virtual...”\n",
    "* **Reason**: \"Ghid\" sounds more accessible and avoids confusion with professional legal advisors. It better reflects the goal of explaining the law in simple terms.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Removed the option to cite legal articles**\n",
    "\n",
    "* **Before**: “Dacă este cazul, poți cita articole de lege...”\n",
    "* **Now**: “Nu cita articole de lege și nu inventa numere de articole.”\n",
    "* **Reason**: Many models (especially Mistral) hallucinate article numbers. Removing this prevents factual errors and misleading answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Clear fallback when information is missing**\n",
    "\n",
    "* **Before**: “...spune că nu poți oferi un răspuns sigur.”\n",
    "* **Now**: “...răspunde cu: „Nu am putut genera un răspuns.””\n",
    "* **Reason**: You wanted a **consistent and predictable fallback** when the context is unclear or insufficient, instead of vague answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Added guidance for short, clear phrasing**\n",
    "\n",
    "* **New rule**: “Scrie răspunsul în propoziții scurte și clare. Poți folosi listă cu puncte, dacă este nevoie.”\n",
    "* **Reason**: Some responses from the models were long and hard to understand. This rule improves clarity and readability.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Overall Goal of the Changes**\n",
    "\n",
    "These updates help the model:\n",
    "\n",
    "* stay grounded in the provided context,\n",
    "* avoid hallucinations,\n",
    "* use simple, readable language,\n",
    "* and fail gracefully when unsure.\n",
    "\n",
    "This makes the testing process **more reliable** and results easier to evaluate.\n",
    "\n",
    "```\n",
    "prompt_v2 = \"\"\"\n",
    "Ești un ghid juridic virtual, care ajută cetățenii să înțeleagă legea pe înțelesul tuturor. \n",
    "\n",
    "Când răspunzi, urmează aceste reguli:\n",
    " - Explică termenii juridici într-un mod clar, ca și cum ai vorbi cu cineva fără pregătire juridică.\n",
    " - Fii concis, dar oferă informații corecte și complete.\n",
    " - Nu cita articole de lege și nu inventa numere de articole.\n",
    " - Scrie răspunsul în propoziții scurte și clare. Poți folosi listă cu puncte, dacă este nevoie.\n",
    " - Nu inventa informații. Dacă informația nu se regăsește clar în contextul oferit, răspunde cu: **„Nu am putut genera un răspuns.”**\n",
    " - Nu oferi sfaturi legale personalizate; explică doar cadrul legal general.\n",
    "\n",
    "Întrebarea utilizatorului este: {question}\n",
    "\n",
    "Folosește următoarele informații extrase din documentele juridice:\n",
    "{context}\n",
    "\n",
    "Răspunsul tău trebuie să fie în limba română, clar, politicos și ușor de înțeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Results:\n",
    "Absolutely! Here's an updated **English summary** based on the **latest results** and your current `prompt_v2`:\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 **Summary of Results for Prompt\\_v2 (Latest Evaluation)**\n",
    "\n",
    "You tested two models — **Rollama3-8b** and **Rollama2-7b** — using a revised legal prompt designed to be clear, concise, and faithful to the provided legal context. Below is a summary of their performance based on four evaluation criteria and grammar quality.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Prompt Used:**\n",
    "\n",
    "```text\n",
    "Ești un ghid juridic virtual, care ajută cetățenii să înțeleagă legea pe înțelesul tuturor. [...] (see full prompt above)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 **Rollama3-8b – Results**\n",
    "\n",
    "* **Answer Relevancy**: 83.3% pass, **avg: 0.884**\n",
    "* **Contextual Recall**: 50% pass, **avg: 0.733**\n",
    "* **Faithfulness**: 50% pass, **avg: 0.622**\n",
    "* **Understanding (GEval)**: 0% pass, **avg: 0.485**\n",
    "\n",
    "### ✅ Grammar and Style\n",
    "\n",
    "* Language is **grammatically correct** and formal.\n",
    "* Answers are **well-structured**, but some are **overly technical**.\n",
    "* Several responses **invent or misstate legal facts** (e.g. 30-day detention).\n",
    "* The use of clear sentence structure has improved, but **clarity for non-experts is still weak**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 **Rollama2-7b – Results**\n",
    "\n",
    "* **Answer Relevancy**: 83.3% pass, **avg: 0.83**\n",
    "* **Contextual Recall**: 50% pass, **avg: 0.733**\n",
    "* **Faithfulness**: 50% pass, **avg: 0.734**\n",
    "* **Understanding (GEval)**: 16.7% pass, **avg: 0.577**\n",
    "\n",
    "### ✅ Grammar and Style\n",
    "\n",
    "* Answers are **slightly more natural and accessible** than Rollama3.\n",
    "* Still contains **legal jargon** and **lengthy explanations**, reducing clarity.\n",
    "* In some cases, **correct legal information is mixed with unrelated details** (e.g. other contract types).\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Conclusions**\n",
    "\n",
    "* Both models improved in **relevance and faithfulness** with the new prompt.\n",
    "* **Rollama3-8b** writes with better grammar and structure, but clarity suffers for non-legal users.\n",
    "* **Rollama2-7b** is a bit more readable but still includes **off-topic or verbose content**.\n",
    "* **Understanding (GEval)** remains the weakest area for both models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e19cbc",
   "metadata": {},
   "source": [
    "### 🔄 **Changes from Prompt\\_v2 to Prompt\\_v3 (Short Summary)**\n",
    "\n",
    "* **Tone and goal** clarified: Prompt\\_v3 opens with a clear description of the assistant’s purpose.\n",
    "* **Simplification rules improved**: Now explicitly tells the model to avoid legal jargon, long sentences, and abstract language.\n",
    "* **Repetition reduced**: Combines and streamlines some instructions (e.g., clarity, conciseness).\n",
    "* **Friendlier tone**: Suggests the assistant should be neutral but approachable.\n",
    "\n",
    "🟢 Overall, **prompt\\_v3 is cleaner, more focused on clarity**, and more accessible for models like Rollama3-8b.\n",
    "\n",
    "```\n",
    "prompt_v3 = \"\"\" \n",
    "Ești un ghid juridic virtual. Scopul tău este să explici legea în limba română într-un mod clar, concis și ușor de înțeles pentru orice cetățean, fără a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "Când răspunzi, respectă aceste reguli:\n",
    " - Răspunsul trebuie să conțină propoziții scurte, clare și fără termeni juridici complicați. Evită frazele lungi.\n",
    " - Explică termenii juridici pe înțelesul oricui, fără a presupune cunoștințe legale.\n",
    " - Nu cita articole de lege și nu inventa surse sau exemple.\n",
    " - Folosește doar informațiile din context. Nu completa cu informații suplimentare.\n",
    " - Dacă contextul nu oferă un răspuns clar, scrie simplu: **„Nu am putut genera un răspuns.”**\n",
    " - Fii concis. Nu scrie mai mult decât este necesar pentru a răspunde clar la întrebare.\n",
    " - Evită limbajul prea tehnic sau abstract. Fii prietenos, dar neutru.\n",
    "\n",
    "Întrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informațiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie răspunsul în limba română. Acesta trebuie să fie clar, politicos și ușor de înțeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "## 🧾 Summary of Results for Prompt\\_v3\n",
    "\n",
    "### ✅ **rollama3-8b-instruct**\n",
    "\n",
    "* **Answer Relevancy**: **0.85 avg** (↑ High)\n",
    "\n",
    "  * Excellent focus on answering the user's question directly in most cases.\n",
    "* **Contextual Recall**: **0.73 avg** (↔️ Same as previous prompts)\n",
    "\n",
    "  * Retrieval alignment is stable, but still limited in some examples.\n",
    "* **Faithfulness**: **0.45 avg** (↓ Dropped)\n",
    "\n",
    "  * A clear regression in factual accuracy — some answers confidently introduced incorrect legal interpretations or misused the context.\n",
    "* **Understanding (GEval)**: **0.54 avg** (↑ Slight improvement)\n",
    "\n",
    "  * Answers were somewhat clearer than prompt\\_v2, but still often failed to fully support lay understanding.\n",
    "\n",
    "📌 **Observation**: While the tone and clarity improved with prompt\\_v3, the **faithfulness took a hit**. This may be due to the freer, more conversational structure allowing the model to drift from strict context.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **rollama2-7b-instruct**\n",
    "\n",
    "* **Answer Relevancy**: **0.60 avg** (↓ Major drop)\n",
    "\n",
    "  * Responses wandered more often or misinterpreted the question.\n",
    "* **Contextual Recall**: **0.76 avg** (↔️ Consistent)\n",
    "* **Faithfulness**: **0.71 avg** (↘ Slight drop)\n",
    "* **Understanding (GEval)**: **0.56 avg** (↔️ Same level)\n",
    "\n",
    "📌 **Observation**: The 7B model **struggled more** with prompt\\_v3. The simpler, relaxed language may not have helped steer it as precisely as the previous prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203055d",
   "metadata": {},
   "source": [
    "**Summary of changes from `prompt_v3` to revised prompt:**\n",
    "\n",
    "* **Stronger constraints on faithfulness:** The revised prompt emphasizes *strict adherence to the context*, explicitly telling the model *not to invent information* or add anything outside the provided text.\n",
    "* **Clearer rejection behavior:** The fallback phrase (\"Nu am putut genera un răspuns\") is now required **only if the context is insufficient**, reinforcing conservative generation.\n",
    "* **Simplified and focused wording:** Instructions are now more direct, avoiding redundancies (e.g. \"fii concis și complet\" replaces two similar sentences).\n",
    "* **Prohibition of generalizations:** The revised prompt discourages extrapolating or general legal assumptions not grounded in the source material.\n",
    "* **Tone guidance retained, but rephrased:** It still instructs the assistant to be polite, neutral, and user-friendly—but with more emphasis on clarity and factual restraint.\n",
    "\n",
    "```\n",
    "prompt_v4 = \"\"\" \n",
    "Ești un ghid juridic virtual. Scopul tău este să explici legea în limba română într-un mod clar, concis și accesibil oricărui cetățean, fără a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "Respectă cu strictețe următoarele reguli:\n",
    " - Scrie propoziții scurte, clare și ușor de înțeles. Evită frazele lungi și ambigue.\n",
    " - Nu folosi termeni juridici specializați. Dacă apar în context, explică-i simplu.\n",
    " - Nu inventa informații și nu completa cu exemple din cunoștințele tale. Fii fidel exclusiv contextului.\n",
    " - Nu cita articole de lege și nu menționa surse sau numere de articole.\n",
    " - Dacă informația necesară nu se găsește în context, scrie exact: **„Nu am putut genera un răspuns.”**\n",
    " - Evită generalizările. Limitează-te doar la ceea ce este prezent în context.\n",
    " - Răspunsul trebuie să fie scurt, complet și fără comentarii inutile.\n",
    " - Păstrează un ton politicos, neutru și prietenos. Nu oferi sfaturi legale personalizate.\n",
    "\n",
    "Uite două exemple de întrebări și răspunsuri pentru a înțelege ce se așteaptă:\n",
    "\n",
    "Exemplu bun:  \n",
    "Întrebare: Ce protecție oferă statul român cetățenilor săi aflați în afara țării?  \n",
    "Răspuns: Cetățenii români aflați în străinătate beneficiază de protecția statului român. Ei trebuie să-și respecte obligațiile, cu excepția celor care nu pot fi îndeplinite din cauza absenței din țară.\n",
    "\n",
    "Exemplu greșit:  \n",
    "Întrebare: Ce drepturi are un chiriaș?  \n",
    "Răspuns: În general, chiriașii au dreptul la o locuință decentă, iar proprietarul nu are voie să-i deranjeze. Dacă ceva nu merge bine, e suficient ca chiriașul să notifice proprietarul pentru a pleca.  \n",
    "(Motive: răspunsul este vag, incomplet și conține informații care nu sunt în contextul oferit.)\n",
    "---\n",
    "\n",
    "Întrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informațiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie răspunsul în limba română. Acesta trebuie să fie clar, politicos și ușor de înțeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "## Summary of results\n",
    "\n",
    "## 📊 rollama3-8b-instruct — Prompt v4 Summary\n",
    "\n",
    "| Metric                    | Avg. Score  | Pass Rate    | Compared to Prompt v3 |\n",
    "| ------------------------- | ----------- | ------------ | --------------------- |\n",
    "| **Answer Relevancy**      | ✅ **0.951** | ✅ **100.0%** | 🔼 Up from 0.848      |\n",
    "| **Contextual Recall**     | ➖ 0.733     | ➖ 50.0%      | ➡️ Same               |\n",
    "| **Faithfulness**          | ⚠️ 0.524    | ⚠️ 33.3%     | 🔼 Up from 0.451      |\n",
    "| **Understanding (GEval)** | ❌ 0.528     | ❌ 0.0%       | 🔽 Down from 0.541    |\n",
    "\n",
    "### ✔ Highlights:\n",
    "\n",
    "* **Big win on Answer Relevancy**: Every answer stays on topic and responds directly to the question.\n",
    "* **Slight improvement in Faithfulness**: The strict instructions about sticking to context are starting to help.\n",
    "\n",
    "### ⚠ Still weak:\n",
    "\n",
    "* **Understanding** dropped slightly. Possibly due to short or overly compressed answers that sacrifice clarity for precision.\n",
    "* **Faithfulness** still suffers from minor hallucinations (e.g., invented exceptions, summaries too creative).\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 rollama2-7b-instruct — Prompt v4 Summary\n",
    "\n",
    "| Metric                    | Avg. Score  | Pass Rate   | Compared to Prompt v3       |\n",
    "| ------------------------- | ----------- | ----------- | --------------------------- |\n",
    "| **Answer Relevancy**      | ⚠️ 0.745    | ⚠️ 66.7%    | 🔼 Up from 0.602            |\n",
    "| **Contextual Recall**     | ➖ 0.722     | ➖ 50.0%     | 🔽 Slightly down from 0.761 |\n",
    "| **Faithfulness**          | ✅ **0.727** | ✅ **66.7%** | 🔼 Up from 0.713            |\n",
    "| **Understanding (GEval)** | ❌ 0.507     | ❌ 0.0%      | 🔽 Down from 0.562          |\n",
    "\n",
    "### ✔ Highlights:\n",
    "\n",
    "* **Improved faithfulness**: 7B seems to follow instructions more rigidly and is less prone to hallucination.\n",
    "* **Better answer relevance**: More answers are on topic compared to v3.\n",
    "\n",
    "### ⚠ Still weak:\n",
    "\n",
    "* **Understanding** is the lowest among all metrics — answers are terse, lack clarity, or include legalese.\n",
    "* **Contextual recall** is inconsistent, and answers often miss key context points even when they sound reasonable.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔚 TL;DR\n",
    "\n",
    "| Metric         | Best Model | Notes                              |\n",
    "| -------------- | ---------- | ---------------------------------- |\n",
    "| Relevancy      | **8B**     | Perfect with Prompt v5.            |\n",
    "| Faithfulness   | **7B**     | More cautious, less hallucination. |\n",
    "| Contextual Use | Tie        | 7B and 8B both hit 50% pass rate.  |\n",
    "| Understanding  | Neither    | Still a major weakness.            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5134e69",
   "metadata": {},
   "source": [
    "### 🔄 Summary of Changes from Prompt v4:\n",
    "\n",
    "1. **Clarified Target Audience**\n",
    "\n",
    "   * Added the phrase *\"for someone without legal education\"* to emphasize that explanations must be layperson-friendly.\n",
    "\n",
    "2. **Improved Instruction for Logical Structure**\n",
    "\n",
    "   * New rule: *\"Begin with the main idea, then explain conditions or exceptions in a natural order.\"*\n",
    "   * This encourages more structured, coherent responses, especially when legal reasoning is involved.\n",
    "\n",
    "3. **Explicit Handling of Conditions and Steps**\n",
    "\n",
    "   * Added guidance: *\"If the answer includes conditions, steps, or exceptions, explain them briefly, clearly, and in logical order.\"*\n",
    "\n",
    "4. **Discouraged Vagueness Even Further**\n",
    "\n",
    "   * Strengthened the prohibition against vague qualifiers (e.g., \"usually\", \"sometimes\") unless explicitly mentioned in context.\n",
    "\n",
    "5. **Minor Wording Refinements**\n",
    "\n",
    "   * Slight rephrasing of existing rules for clarity (e.g., replacing “limbaj complicat” with “fraze lungi sau ambigue”).\n",
    "\n",
    "```\n",
    "prompt_v5 = \"\"\" \n",
    "Ești un ghid juridic virtual. Scopul tău este să explici legea în limba română într-un mod clar, concis și accesibil oricărui cetățean, fără a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "Respectă cu strictețe următoarele reguli:\n",
    " - Scrie propoziții scurte, clare și ușor de înțeles pentru cineva fără studii juridice. Evită frazele lungi sau ambigue.\n",
    " - Nu folosi termeni juridici specializați. Dacă apar în context, explică-i simplu.\n",
    " - Dacă răspunsul implică condiții, pași sau excepții, explică-le pe scurt, clar și logic, într-o ordine firească.\n",
    " - Structura răspunsului trebuie să urmeze o ordine logică. Începe cu ideea principală, apoi oferă explicații sau condiții, dacă există.\n",
    " - Nu inventa informații și nu completa cu exemple din cunoștințele tale. Fii fidel exclusiv contextului.\n",
    " - Nu cita articole de lege și nu menționa surse sau numere de articole.\n",
    " - Dacă informația necesară nu se găsește în context, scrie exact: **„Nu am putut genera un răspuns.”**\n",
    " - Evită generalizările. Limitează-te doar la ceea ce este prezent în context.\n",
    " - Nu folosi formulări vagi precum „în general”, „uneori” sau „de obicei”, decât dacă apar în context.\n",
    " - Răspunsul trebuie să fie scurt, complet și fără comentarii inutile.\n",
    " - Păstrează un ton politicos, neutru și prietenos. Nu oferi sfaturi legale personalizate.\n",
    "\n",
    "Uite două exemple de întrebări și răspunsuri pentru a înțelege ce se așteaptă:\n",
    "\n",
    "Exemplu bun:  \n",
    "Întrebare: Ce protecție oferă statul român cetățenilor săi aflați în afara țării?  \n",
    "Răspuns: Cetățenii români aflați în străinătate beneficiază de protecția statului român. Ei trebuie să-și respecte obligațiile, cu excepția celor care nu pot fi îndeplinite din cauza absenței din țară.\n",
    "\n",
    "Exemplu greșit:  \n",
    "Întrebare: Ce drepturi are un chiriaș?  \n",
    "Răspuns: În general, chiriașii au dreptul la o locuință decentă, iar proprietarul nu are voie să-i deranjeze. Dacă ceva nu merge bine, e suficient ca chiriașul să notifice proprietarul pentru a pleca.  \n",
    "(Motive: răspunsul este vag, incomplet și conține informații care nu sunt în contextul oferit.)\n",
    "---\n",
    "\n",
    "Întrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informațiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie răspunsul în limba română. Acesta trebuie să fie clar, politicos și ușor de înțeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "### 🔹 **rollama3-8b-instruct — Prompt 5 Summary**\n",
    "\n",
    "| Metric                | Score | Pass Rate |\n",
    "| --------------------- | ----- | --------- |\n",
    "| Answer Relevancy      | 0.785 | 50%       |\n",
    "| Contextual Recall     | 0.761 | 50%       |\n",
    "| Faithfulness          | 0.488 | 50%       |\n",
    "| Understanding (GEval) | 0.489 | 0%        |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* **Understanding remains low**, with 0% pass rate, indicating that answers were still not consistently clear or accessible to laypeople.\n",
    "* **Answer Relevancy and Contextual Recall are decent**, but they dropped slightly compared to Prompt 4, suggesting the prompt may have pushed the model to elaborate or speculate more.\n",
    "* **Faithfulness improved modestly** (50% pass rate vs. 33% in Prompt 4), but still suffers due to hallucinated legal details or misinterpretation of the context.\n",
    "* Some outputs **added extra legal context** or speculated on procedures (e.g., arrest duration, contract formality), hurting faithfulness and clarity.\n",
    "\n",
    "**Takeaway:**\n",
    "Prompt 5 did not significantly improve model understanding. It introduced a minor boost in faithfulness and kept contextual alignment steady, but clarity and simplicity for non-experts did not improve, possibly due to over-detailed or over-legalistic generation.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **rollama2-7b-instruct — Prompt 5 Summary**\n",
    "\n",
    "| Metric                | Score | Pass Rate |\n",
    "| --------------------- | ----- | --------- |\n",
    "| Answer Relevancy      | 0.844 | 66.7%     |\n",
    "| Contextual Recall     | 0.733 | 50%       |\n",
    "| Faithfulness          | 0.620 | 33.3%     |\n",
    "| Understanding (GEval) | 0.485 | 0%        |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* **Relevancy improved** significantly compared to Prompt 4, indicating that the model responded more directly to questions.\n",
    "* **Understanding still scored poorly**, failing all GEval checks, meaning the output remains too ambiguous, verbose, or poorly structured for a layperson.\n",
    "* **Faithfulness was inconsistent**: one-third of answers failed due to added assumptions, vague exceptions, or unsupported legal claims.\n",
    "* A few responses **misrepresented legal structures** (e.g., age for marriage, contract validity), indicating prompt constraints were insufficient to prevent hallucination.\n",
    "\n",
    "**Takeaway:**\n",
    "Prompt 5 helped Rollama2 become more relevant and aligned with context, but failed to address core issues with user-friendly understanding and hallucination. It may have encouraged verbosity and added legal complexity that confused the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a17c9",
   "metadata": {},
   "source": [
    "## ✅ Final Conclusion\n",
    "\n",
    "After testing five versions of the prompt, we decided to **stick with Prompt v4**, which achieves the most balanced performance in terms of **clarity**, **faithfulness**, and **realistic output quality**—especially when used with the `rollama3-8b-instruct` model.\n",
    "\n",
    "### 🔹 Why Prompt v4?\n",
    "\n",
    "Compared to earlier prompts, Prompt v4 introduces key improvements:\n",
    "\n",
    "* **Stricter grounding**: The model is explicitly instructed to use *only* the provided context, which reduces hallucinations and off-topic responses.\n",
    "* **Controlled fallback behavior**: The default message “Nu am putut genera un răspuns.” is used only when the context is clearly insufficient.\n",
    "* **Simplified tone and structure**: Rules are more concise and directive, improving the model's response focus and reducing ambiguity.\n",
    "* **User-friendly phrasing**: Maintains a polite, accessible tone appropriate for a non-expert audience, especially in legal contexts.\n",
    "\n",
    "### 📊 Model Performance Recap (Prompt v4)\n",
    "\n",
    "| Metric             | rollama3-8b-instruct | rollama2-7b-instruct | Best Model |\n",
    "| ------------------ | -------------------- | -------------------- | ---------- |\n",
    "| **Relevancy**      | ✅ **0.951** (100%)   | ⚠️ 0.745 (66.7%)     | ✅ 8B       |\n",
    "| **Faithfulness**   | ⚠️ 0.524 (33.3%)     | ✅ **0.727** (66.7%)  | ✅ 7B       |\n",
    "| **Contextual Use** | ➖ 0.733 (50%)        | ➖ 0.722 (50%)        | Tie        |\n",
    "| **Understanding**  | ❌ 0.528              | ❌ 0.507              | Neither    |\n",
    "\n",
    "> ⚠️ Even though **Understanding (GEval)** did not reach the desired 0.7 threshold, the **0.52 average** for the 8B model is **a solid result**, given that the source material consists of dense legal texts with complex structure. For the intended user-facing task (explaining law in plain Romanian), this is **an acceptable and encouraging performance baseline**.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Final Recommendation\n",
    "\n",
    "We recommend using **`rollama3-8b-instruct` with Prompt v4** for production:\n",
    "\n",
    "* ✅ **Best answer relevancy**: All responses are clearly aligned with user queries.\n",
    "* ✅ **Better grammar and natural phrasing**, more suitable for end-user deployment.\n",
    "* ⚠️ **Faithfulness is lower** than 7B, but acceptable considering the gain in clarity and fluidity.\n",
    "* ⚠️ **Understanding** remains below threshold, but is reasonable given the legal complexity.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
