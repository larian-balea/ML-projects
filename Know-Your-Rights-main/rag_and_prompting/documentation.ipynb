{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4f2543",
   "metadata": {},
   "source": [
    "## Model Selection Summary for Legal RAG Application (Romanian)\n",
    "\n",
    "### Goal\n",
    "\n",
    "We are building a Retrieval-Augmented Generation (RAG) application that answers legal questions using Romanian legal texts like the Constitution and laws. The answers must be in Romanian, and the model has to run locally.\n",
    "\n",
    "### Research Process\n",
    "\n",
    "1. **Language support**\n",
    "   We looked for models that understand and generate Romanian well. Legal texts require precise language, so this was a key point.\n",
    "\n",
    "2. **Size and efficiency**\n",
    "   We needed models that are small enough to run on local machines, ideally in quantized format (like Q4), and compatible with LM Studio.\n",
    "\n",
    "3. **Model availability**\n",
    "   To make things easier, we focused on models available on Hugging Face, especially those that can be downloaded in GGUF format.\n",
    "\n",
    "### Models Chosen\n",
    "\n",
    "We decided to test three models:\n",
    "\n",
    "1. **RoLlama2-7b-Instruct-GGUF (Q4)**\n",
    "   A Romanian language model based on LLaMA 2. It's small, trained on Romanian data, and works well on local hardware.\n",
    "\n",
    "2. **NikolayKozloff/RoLlama3-8b-Instruct-Q4\\_0-GGUF**\n",
    "   Based on LLaMA 3, this model is also focused on Romanian and has better performance. It's available in a quantized format for local use.\n",
    "\n",
    "3. **Mistral-7B-Instruct (multilingual)**\n",
    "   A general-purpose model trained on many languages. It wasn‚Äôt trained specifically on Romanian, but we included it to compare how a multilingual model performs against Romanian-only models.\n",
    "\n",
    "### Why These Models?\n",
    "\n",
    "These three models give us a good balance:\n",
    "\n",
    "* Two models specialized in Romanian, including legal use.\n",
    "* One multilingual model to compare performance.\n",
    "* All are available on Hugging Face and compatible with LM Studio.\n",
    "* All can run locally in quantized format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b5374",
   "metadata": {},
   "source": [
    "### **Summary of Romanian Prompt Testing for Three Models**\n",
    "\n",
    "I tested three language models ‚Äî **Rollama3-8b**, **Rollama2-7b**, and **Mistral** ‚Äî on six legal questions in Romanian. Each model‚Äôs responses were evaluated based on four key aspects: **relevance** (if the answer matches the question), **recall** (if it uses the correct information), **faithfulness** (if it‚Äôs factually accurate), and **understanding** (if it‚Äôs easy to read).\n",
    "\n",
    "#### ‚úÖ Rollama3-8b\n",
    "\n",
    "* This model had the **best results overall**.\n",
    "* **4 out of 6 answers** passed at least two evaluation tests.\n",
    "* The answers were **grammatically correct** and mostly accurate.\n",
    "* However, some responses were **too long and complicated**, which made them harder to understand.\n",
    "\n",
    "#### ‚ö†Ô∏è Rollama2-7b\n",
    "\n",
    "* Performance was **average**.\n",
    "* It gave **3 strong answers** out of 6.\n",
    "* The language was sometimes **easier to read** than Rollama3, but there were **grammar mistakes** and **some incorrect or missing legal facts**.\n",
    "* Still, it could be a decent alternative depending on the use case.\n",
    "\n",
    "#### ‚ùå Mistral\n",
    "\n",
    "* This model had the **worst performance**.\n",
    "* Although **4 answers passed** two tests, **one answer failed all tests**.\n",
    "* The grammar was **poor**, and many sentences were **confusing or incorrect**.\n",
    "* The output often included **nonsense words**, **contradictions**, or **legal errors**.\n",
    "\n",
    "I **expected Mistral to perform poorly** since it wasn‚Äôt trained on Romanian data. Because of this and its low quality, I‚Äôve decided to **drop Mistral** from my testing process. This will also help make the prompt testing process **faster and more focused**.\n",
    "```\n",
    "prompt = \"\"\"\n",
    "E»ôti un asistent juridic virtual, specializat √Æn explicarea drepturilor cetƒÉ»õenilor √Æntr-un limbaj simplu »ôi accesibil. RƒÉspunzi √Æn limba rom√¢nƒÉ, folosind informa»õiile din documente juridice oficiale precum Constitu»õia Rom√¢niei, Codul Muncii sau alte acte normative relevante.\n",
    "\n",
    "C√¢nd rƒÉspunzi, urmeazƒÉ aceste reguli:\n",
    " - ExplicƒÉ termenii juridici √Æntr-un mod clar, ca »ôi cum ai vorbi cu cineva fƒÉrƒÉ pregƒÉtire juridicƒÉ.\n",
    " - Fii concis, dar oferƒÉ informa»õii corecte »ôi complete.\n",
    " - DacƒÉ este cazul, po»õi cita articole de lege (ex: ‚ÄûConform articolului X din Codul Muncii...‚Äù).\n",
    " - Nu inventa informa»õii. DacƒÉ √Æntrebarea nu are un rƒÉspuns clar √Æn documentele juridice disponibile, spune cƒÉ nu po»õi oferi un rƒÉspuns sigur.\n",
    " - Nu oferi sfaturi legale personalizate; explicƒÉ doar cadrul legal general.\n",
    "\n",
    "√éntrebarea utilizatorului este: {question}\n",
    "\n",
    "Folose»ôte urmƒÉtoarele informa»õii extrase din documentele juridice:\n",
    "{context}\n",
    "\n",
    "RƒÉspunsul tƒÉu trebuie sƒÉ fie √Æn limba rom√¢nƒÉ, clar, politicos »ôi u»ôor de √Æn»õeles.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a99d6",
   "metadata": {},
   "source": [
    "### **Summary of Prompt Changes and Their Purpose**\n",
    "\n",
    "You updated your prompt to improve the quality and reliability of answers in Romanian, especially when testing models like Rollama and Mistral. Below are the main changes you made and why:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Changed role from ‚Äúasistent juridic‚Äù to ‚Äúghid juridic‚Äù**\n",
    "\n",
    "* **Before**: ‚ÄúE»ôti un asistent juridic virtual...‚Äù\n",
    "* **Now**: ‚ÄúE»ôti un ghid juridic virtual...‚Äù\n",
    "* **Reason**: \"Ghid\" sounds more accessible and avoids confusion with professional legal advisors. It better reflects the goal of explaining the law in simple terms.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Removed the option to cite legal articles**\n",
    "\n",
    "* **Before**: ‚ÄúDacƒÉ este cazul, po»õi cita articole de lege...‚Äù\n",
    "* **Now**: ‚ÄúNu cita articole de lege »ôi nu inventa numere de articole.‚Äù\n",
    "* **Reason**: Many models (especially Mistral) hallucinate article numbers. Removing this prevents factual errors and misleading answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Clear fallback when information is missing**\n",
    "\n",
    "* **Before**: ‚Äú...spune cƒÉ nu po»õi oferi un rƒÉspuns sigur.‚Äù\n",
    "* **Now**: ‚Äú...rƒÉspunde cu: ‚ÄûNu am putut genera un rƒÉspuns.‚Äù‚Äù\n",
    "* **Reason**: You wanted a **consistent and predictable fallback** when the context is unclear or insufficient, instead of vague answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Added guidance for short, clear phrasing**\n",
    "\n",
    "* **New rule**: ‚ÄúScrie rƒÉspunsul √Æn propozi»õii scurte »ôi clare. Po»õi folosi listƒÉ cu puncte, dacƒÉ este nevoie.‚Äù\n",
    "* **Reason**: Some responses from the models were long and hard to understand. This rule improves clarity and readability.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Overall Goal of the Changes**\n",
    "\n",
    "These updates help the model:\n",
    "\n",
    "* stay grounded in the provided context,\n",
    "* avoid hallucinations,\n",
    "* use simple, readable language,\n",
    "* and fail gracefully when unsure.\n",
    "\n",
    "This makes the testing process **more reliable** and results easier to evaluate.\n",
    "\n",
    "```\n",
    "prompt_v2 = \"\"\"\n",
    "E»ôti un ghid juridic virtual, care ajutƒÉ cetƒÉ»õenii sƒÉ √Æn»õeleagƒÉ legea pe √Æn»õelesul tuturor. \n",
    "\n",
    "C√¢nd rƒÉspunzi, urmeazƒÉ aceste reguli:\n",
    " - ExplicƒÉ termenii juridici √Æntr-un mod clar, ca »ôi cum ai vorbi cu cineva fƒÉrƒÉ pregƒÉtire juridicƒÉ.\n",
    " - Fii concis, dar oferƒÉ informa»õii corecte »ôi complete.\n",
    " - Nu cita articole de lege »ôi nu inventa numere de articole.\n",
    " - Scrie rƒÉspunsul √Æn propozi»õii scurte »ôi clare. Po»õi folosi listƒÉ cu puncte, dacƒÉ este nevoie.\n",
    " - Nu inventa informa»õii. DacƒÉ informa»õia nu se regƒÉse»ôte clar √Æn contextul oferit, rƒÉspunde cu: **‚ÄûNu am putut genera un rƒÉspuns.‚Äù**\n",
    " - Nu oferi sfaturi legale personalizate; explicƒÉ doar cadrul legal general.\n",
    "\n",
    "√éntrebarea utilizatorului este: {question}\n",
    "\n",
    "Folose»ôte urmƒÉtoarele informa»õii extrase din documentele juridice:\n",
    "{context}\n",
    "\n",
    "RƒÉspunsul tƒÉu trebuie sƒÉ fie √Æn limba rom√¢nƒÉ, clar, politicos »ôi u»ôor de √Æn»õeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Results:\n",
    "Absolutely! Here's an updated **English summary** based on the **latest results** and your current `prompt_v2`:\n",
    "\n",
    "---\n",
    "\n",
    "### üìù **Summary of Results for Prompt\\_v2 (Latest Evaluation)**\n",
    "\n",
    "You tested two models ‚Äî **Rollama3-8b** and **Rollama2-7b** ‚Äî using a revised legal prompt designed to be clear, concise, and faithful to the provided legal context. Below is a summary of their performance based on four evaluation criteria and grammar quality.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Prompt Used:**\n",
    "\n",
    "```text\n",
    "E»ôti un ghid juridic virtual, care ajutƒÉ cetƒÉ»õenii sƒÉ √Æn»õeleagƒÉ legea pe √Æn»õelesul tuturor. [...] (see full prompt above)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ **Rollama3-8b ‚Äì Results**\n",
    "\n",
    "* **Answer Relevancy**: 83.3% pass, **avg: 0.884**\n",
    "* **Contextual Recall**: 50% pass, **avg: 0.733**\n",
    "* **Faithfulness**: 50% pass, **avg: 0.622**\n",
    "* **Understanding (GEval)**: 0% pass, **avg: 0.485**\n",
    "\n",
    "### ‚úÖ Grammar and Style\n",
    "\n",
    "* Language is **grammatically correct** and formal.\n",
    "* Answers are **well-structured**, but some are **overly technical**.\n",
    "* Several responses **invent or misstate legal facts** (e.g. 30-day detention).\n",
    "* The use of clear sentence structure has improved, but **clarity for non-experts is still weak**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ **Rollama2-7b ‚Äì Results**\n",
    "\n",
    "* **Answer Relevancy**: 83.3% pass, **avg: 0.83**\n",
    "* **Contextual Recall**: 50% pass, **avg: 0.733**\n",
    "* **Faithfulness**: 50% pass, **avg: 0.734**\n",
    "* **Understanding (GEval)**: 16.7% pass, **avg: 0.577**\n",
    "\n",
    "### ‚úÖ Grammar and Style\n",
    "\n",
    "* Answers are **slightly more natural and accessible** than Rollama3.\n",
    "* Still contains **legal jargon** and **lengthy explanations**, reducing clarity.\n",
    "* In some cases, **correct legal information is mixed with unrelated details** (e.g. other contract types).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Conclusions**\n",
    "\n",
    "* Both models improved in **relevance and faithfulness** with the new prompt.\n",
    "* **Rollama3-8b** writes with better grammar and structure, but clarity suffers for non-legal users.\n",
    "* **Rollama2-7b** is a bit more readable but still includes **off-topic or verbose content**.\n",
    "* **Understanding (GEval)** remains the weakest area for both models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e19cbc",
   "metadata": {},
   "source": [
    "### üîÑ **Changes from Prompt\\_v2 to Prompt\\_v3 (Short Summary)**\n",
    "\n",
    "* **Tone and goal** clarified: Prompt\\_v3 opens with a clear description of the assistant‚Äôs purpose.\n",
    "* **Simplification rules improved**: Now explicitly tells the model to avoid legal jargon, long sentences, and abstract language.\n",
    "* **Repetition reduced**: Combines and streamlines some instructions (e.g., clarity, conciseness).\n",
    "* **Friendlier tone**: Suggests the assistant should be neutral but approachable.\n",
    "\n",
    "üü¢ Overall, **prompt\\_v3 is cleaner, more focused on clarity**, and more accessible for models like Rollama3-8b.\n",
    "\n",
    "```\n",
    "prompt_v3 = \"\"\" \n",
    "E»ôti un ghid juridic virtual. Scopul tƒÉu este sƒÉ explici legea √Æn limba rom√¢nƒÉ √Æntr-un mod clar, concis »ôi u»ôor de √Æn»õeles pentru orice cetƒÉ»õean, fƒÉrƒÉ a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "C√¢nd rƒÉspunzi, respectƒÉ aceste reguli:\n",
    " - RƒÉspunsul trebuie sƒÉ con»õinƒÉ propozi»õii scurte, clare »ôi fƒÉrƒÉ termeni juridici complica»õi. EvitƒÉ frazele lungi.\n",
    " - ExplicƒÉ termenii juridici pe √Æn»õelesul oricui, fƒÉrƒÉ a presupune cuno»ôtin»õe legale.\n",
    " - Nu cita articole de lege »ôi nu inventa surse sau exemple.\n",
    " - Folose»ôte doar informa»õiile din context. Nu completa cu informa»õii suplimentare.\n",
    " - DacƒÉ contextul nu oferƒÉ un rƒÉspuns clar, scrie simplu: **‚ÄûNu am putut genera un rƒÉspuns.‚Äù**\n",
    " - Fii concis. Nu scrie mai mult dec√¢t este necesar pentru a rƒÉspunde clar la √Æntrebare.\n",
    " - EvitƒÉ limbajul prea tehnic sau abstract. Fii prietenos, dar neutru.\n",
    "\n",
    "√éntrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informa»õiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie rƒÉspunsul √Æn limba rom√¢nƒÉ. Acesta trebuie sƒÉ fie clar, politicos »ôi u»ôor de √Æn»õeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "## üßæ Summary of Results for Prompt\\_v3\n",
    "\n",
    "### ‚úÖ **rollama3-8b-instruct**\n",
    "\n",
    "* **Answer Relevancy**: **0.85 avg** (‚Üë High)\n",
    "\n",
    "  * Excellent focus on answering the user's question directly in most cases.\n",
    "* **Contextual Recall**: **0.73 avg** (‚ÜîÔ∏è Same as previous prompts)\n",
    "\n",
    "  * Retrieval alignment is stable, but still limited in some examples.\n",
    "* **Faithfulness**: **0.45 avg** (‚Üì Dropped)\n",
    "\n",
    "  * A clear regression in factual accuracy ‚Äî some answers confidently introduced incorrect legal interpretations or misused the context.\n",
    "* **Understanding (GEval)**: **0.54 avg** (‚Üë Slight improvement)\n",
    "\n",
    "  * Answers were somewhat clearer than prompt\\_v2, but still often failed to fully support lay understanding.\n",
    "\n",
    "üìå **Observation**: While the tone and clarity improved with prompt\\_v3, the **faithfulness took a hit**. This may be due to the freer, more conversational structure allowing the model to drift from strict context.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **rollama2-7b-instruct**\n",
    "\n",
    "* **Answer Relevancy**: **0.60 avg** (‚Üì Major drop)\n",
    "\n",
    "  * Responses wandered more often or misinterpreted the question.\n",
    "* **Contextual Recall**: **0.76 avg** (‚ÜîÔ∏è Consistent)\n",
    "* **Faithfulness**: **0.71 avg** (‚Üò Slight drop)\n",
    "* **Understanding (GEval)**: **0.56 avg** (‚ÜîÔ∏è Same level)\n",
    "\n",
    "üìå **Observation**: The 7B model **struggled more** with prompt\\_v3. The simpler, relaxed language may not have helped steer it as precisely as the previous prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203055d",
   "metadata": {},
   "source": [
    "**Summary of changes from `prompt_v3` to revised prompt:**\n",
    "\n",
    "* **Stronger constraints on faithfulness:** The revised prompt emphasizes *strict adherence to the context*, explicitly telling the model *not to invent information* or add anything outside the provided text.\n",
    "* **Clearer rejection behavior:** The fallback phrase (\"Nu am putut genera un rƒÉspuns\") is now required **only if the context is insufficient**, reinforcing conservative generation.\n",
    "* **Simplified and focused wording:** Instructions are now more direct, avoiding redundancies (e.g. \"fii concis »ôi complet\" replaces two similar sentences).\n",
    "* **Prohibition of generalizations:** The revised prompt discourages extrapolating or general legal assumptions not grounded in the source material.\n",
    "* **Tone guidance retained, but rephrased:** It still instructs the assistant to be polite, neutral, and user-friendly‚Äîbut with more emphasis on clarity and factual restraint.\n",
    "\n",
    "```\n",
    "prompt_v4 = \"\"\" \n",
    "E»ôti un ghid juridic virtual. Scopul tƒÉu este sƒÉ explici legea √Æn limba rom√¢nƒÉ √Æntr-un mod clar, concis »ôi accesibil oricƒÉrui cetƒÉ»õean, fƒÉrƒÉ a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "RespectƒÉ cu stricte»õe urmƒÉtoarele reguli:\n",
    " - Scrie propozi»õii scurte, clare »ôi u»ôor de √Æn»õeles. EvitƒÉ frazele lungi »ôi ambigue.\n",
    " - Nu folosi termeni juridici specializa»õi. DacƒÉ apar √Æn context, explicƒÉ-i simplu.\n",
    " - Nu inventa informa»õii »ôi nu completa cu exemple din cuno»ôtin»õele tale. Fii fidel exclusiv contextului.\n",
    " - Nu cita articole de lege »ôi nu men»õiona surse sau numere de articole.\n",
    " - DacƒÉ informa»õia necesarƒÉ nu se gƒÉse»ôte √Æn context, scrie exact: **‚ÄûNu am putut genera un rƒÉspuns.‚Äù**\n",
    " - EvitƒÉ generalizƒÉrile. LimiteazƒÉ-te doar la ceea ce este prezent √Æn context.\n",
    " - RƒÉspunsul trebuie sƒÉ fie scurt, complet »ôi fƒÉrƒÉ comentarii inutile.\n",
    " - PƒÉstreazƒÉ un ton politicos, neutru »ôi prietenos. Nu oferi sfaturi legale personalizate.\n",
    "\n",
    "Uite douƒÉ exemple de √ÆntrebƒÉri »ôi rƒÉspunsuri pentru a √Æn»õelege ce se a»ôteaptƒÉ:\n",
    "\n",
    "Exemplu bun:  \n",
    "√éntrebare: Ce protec»õie oferƒÉ statul rom√¢n cetƒÉ»õenilor sƒÉi afla»õi √Æn afara »õƒÉrii?  \n",
    "RƒÉspuns: CetƒÉ»õenii rom√¢ni afla»õi √Æn strƒÉinƒÉtate beneficiazƒÉ de protec»õia statului rom√¢n. Ei trebuie sƒÉ-»ôi respecte obliga»õiile, cu excep»õia celor care nu pot fi √Ændeplinite din cauza absen»õei din »õarƒÉ.\n",
    "\n",
    "Exemplu gre»ôit:  \n",
    "√éntrebare: Ce drepturi are un chiria»ô?  \n",
    "RƒÉspuns: √én general, chiria»ôii au dreptul la o locuin»õƒÉ decentƒÉ, iar proprietarul nu are voie sƒÉ-i deranjeze. DacƒÉ ceva nu merge bine, e suficient ca chiria»ôul sƒÉ notifice proprietarul pentru a pleca.  \n",
    "(Motive: rƒÉspunsul este vag, incomplet »ôi con»õine informa»õii care nu sunt √Æn contextul oferit.)\n",
    "---\n",
    "\n",
    "√éntrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informa»õiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie rƒÉspunsul √Æn limba rom√¢nƒÉ. Acesta trebuie sƒÉ fie clar, politicos »ôi u»ôor de √Æn»õeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "## Summary of results\n",
    "\n",
    "## üìä rollama3-8b-instruct ‚Äî Prompt v4 Summary\n",
    "\n",
    "| Metric                    | Avg. Score  | Pass Rate    | Compared to Prompt v3 |\n",
    "| ------------------------- | ----------- | ------------ | --------------------- |\n",
    "| **Answer Relevancy**      | ‚úÖ **0.951** | ‚úÖ **100.0%** | üîº Up from 0.848      |\n",
    "| **Contextual Recall**     | ‚ûñ 0.733     | ‚ûñ 50.0%      | ‚û°Ô∏è Same               |\n",
    "| **Faithfulness**          | ‚ö†Ô∏è 0.524    | ‚ö†Ô∏è 33.3%     | üîº Up from 0.451      |\n",
    "| **Understanding (GEval)** | ‚ùå 0.528     | ‚ùå 0.0%       | üîΩ Down from 0.541    |\n",
    "\n",
    "### ‚úî Highlights:\n",
    "\n",
    "* **Big win on Answer Relevancy**: Every answer stays on topic and responds directly to the question.\n",
    "* **Slight improvement in Faithfulness**: The strict instructions about sticking to context are starting to help.\n",
    "\n",
    "### ‚ö† Still weak:\n",
    "\n",
    "* **Understanding** dropped slightly. Possibly due to short or overly compressed answers that sacrifice clarity for precision.\n",
    "* **Faithfulness** still suffers from minor hallucinations (e.g., invented exceptions, summaries too creative).\n",
    "\n",
    "---\n",
    "\n",
    "## üìä rollama2-7b-instruct ‚Äî Prompt v4 Summary\n",
    "\n",
    "| Metric                    | Avg. Score  | Pass Rate   | Compared to Prompt v3       |\n",
    "| ------------------------- | ----------- | ----------- | --------------------------- |\n",
    "| **Answer Relevancy**      | ‚ö†Ô∏è 0.745    | ‚ö†Ô∏è 66.7%    | üîº Up from 0.602            |\n",
    "| **Contextual Recall**     | ‚ûñ 0.722     | ‚ûñ 50.0%     | üîΩ Slightly down from 0.761 |\n",
    "| **Faithfulness**          | ‚úÖ **0.727** | ‚úÖ **66.7%** | üîº Up from 0.713            |\n",
    "| **Understanding (GEval)** | ‚ùå 0.507     | ‚ùå 0.0%      | üîΩ Down from 0.562          |\n",
    "\n",
    "### ‚úî Highlights:\n",
    "\n",
    "* **Improved faithfulness**: 7B seems to follow instructions more rigidly and is less prone to hallucination.\n",
    "* **Better answer relevance**: More answers are on topic compared to v3.\n",
    "\n",
    "### ‚ö† Still weak:\n",
    "\n",
    "* **Understanding** is the lowest among all metrics ‚Äî answers are terse, lack clarity, or include legalese.\n",
    "* **Contextual recall** is inconsistent, and answers often miss key context points even when they sound reasonable.\n",
    "\n",
    "---\n",
    "\n",
    "## üîö TL;DR\n",
    "\n",
    "| Metric         | Best Model | Notes                              |\n",
    "| -------------- | ---------- | ---------------------------------- |\n",
    "| Relevancy      | **8B**     | Perfect with Prompt v5.            |\n",
    "| Faithfulness   | **7B**     | More cautious, less hallucination. |\n",
    "| Contextual Use | Tie        | 7B and 8B both hit 50% pass rate.  |\n",
    "| Understanding  | Neither    | Still a major weakness.            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5134e69",
   "metadata": {},
   "source": [
    "### üîÑ Summary of Changes from Prompt v4:\n",
    "\n",
    "1. **Clarified Target Audience**\n",
    "\n",
    "   * Added the phrase *\"for someone without legal education\"* to emphasize that explanations must be layperson-friendly.\n",
    "\n",
    "2. **Improved Instruction for Logical Structure**\n",
    "\n",
    "   * New rule: *\"Begin with the main idea, then explain conditions or exceptions in a natural order.\"*\n",
    "   * This encourages more structured, coherent responses, especially when legal reasoning is involved.\n",
    "\n",
    "3. **Explicit Handling of Conditions and Steps**\n",
    "\n",
    "   * Added guidance: *\"If the answer includes conditions, steps, or exceptions, explain them briefly, clearly, and in logical order.\"*\n",
    "\n",
    "4. **Discouraged Vagueness Even Further**\n",
    "\n",
    "   * Strengthened the prohibition against vague qualifiers (e.g., \"usually\", \"sometimes\") unless explicitly mentioned in context.\n",
    "\n",
    "5. **Minor Wording Refinements**\n",
    "\n",
    "   * Slight rephrasing of existing rules for clarity (e.g., replacing ‚Äúlimbaj complicat‚Äù with ‚Äúfraze lungi sau ambigue‚Äù).\n",
    "\n",
    "```\n",
    "prompt_v5 = \"\"\" \n",
    "E»ôti un ghid juridic virtual. Scopul tƒÉu este sƒÉ explici legea √Æn limba rom√¢nƒÉ √Æntr-un mod clar, concis »ôi accesibil oricƒÉrui cetƒÉ»õean, fƒÉrƒÉ a folosi termeni tehnici sau limbaj complicat.\n",
    "\n",
    "RespectƒÉ cu stricte»õe urmƒÉtoarele reguli:\n",
    " - Scrie propozi»õii scurte, clare »ôi u»ôor de √Æn»õeles pentru cineva fƒÉrƒÉ studii juridice. EvitƒÉ frazele lungi sau ambigue.\n",
    " - Nu folosi termeni juridici specializa»õi. DacƒÉ apar √Æn context, explicƒÉ-i simplu.\n",
    " - DacƒÉ rƒÉspunsul implicƒÉ condi»õii, pa»ôi sau excep»õii, explicƒÉ-le pe scurt, clar »ôi logic, √Æntr-o ordine fireascƒÉ.\n",
    " - Structura rƒÉspunsului trebuie sƒÉ urmeze o ordine logicƒÉ. √éncepe cu ideea principalƒÉ, apoi oferƒÉ explica»õii sau condi»õii, dacƒÉ existƒÉ.\n",
    " - Nu inventa informa»õii »ôi nu completa cu exemple din cuno»ôtin»õele tale. Fii fidel exclusiv contextului.\n",
    " - Nu cita articole de lege »ôi nu men»õiona surse sau numere de articole.\n",
    " - DacƒÉ informa»õia necesarƒÉ nu se gƒÉse»ôte √Æn context, scrie exact: **‚ÄûNu am putut genera un rƒÉspuns.‚Äù**\n",
    " - EvitƒÉ generalizƒÉrile. LimiteazƒÉ-te doar la ceea ce este prezent √Æn context.\n",
    " - Nu folosi formulƒÉri vagi precum ‚Äû√Æn general‚Äù, ‚Äûuneori‚Äù sau ‚Äûde obicei‚Äù, dec√¢t dacƒÉ apar √Æn context.\n",
    " - RƒÉspunsul trebuie sƒÉ fie scurt, complet »ôi fƒÉrƒÉ comentarii inutile.\n",
    " - PƒÉstreazƒÉ un ton politicos, neutru »ôi prietenos. Nu oferi sfaturi legale personalizate.\n",
    "\n",
    "Uite douƒÉ exemple de √ÆntrebƒÉri »ôi rƒÉspunsuri pentru a √Æn»õelege ce se a»ôteaptƒÉ:\n",
    "\n",
    "Exemplu bun:  \n",
    "√éntrebare: Ce protec»õie oferƒÉ statul rom√¢n cetƒÉ»õenilor sƒÉi afla»õi √Æn afara »õƒÉrii?  \n",
    "RƒÉspuns: CetƒÉ»õenii rom√¢ni afla»õi √Æn strƒÉinƒÉtate beneficiazƒÉ de protec»õia statului rom√¢n. Ei trebuie sƒÉ-»ôi respecte obliga»õiile, cu excep»õia celor care nu pot fi √Ændeplinite din cauza absen»õei din »õarƒÉ.\n",
    "\n",
    "Exemplu gre»ôit:  \n",
    "√éntrebare: Ce drepturi are un chiria»ô?  \n",
    "RƒÉspuns: √én general, chiria»ôii au dreptul la o locuin»õƒÉ decentƒÉ, iar proprietarul nu are voie sƒÉ-i deranjeze. DacƒÉ ceva nu merge bine, e suficient ca chiria»ôul sƒÉ notifice proprietarul pentru a pleca.  \n",
    "(Motive: rƒÉspunsul este vag, incomplet »ôi con»õine informa»õii care nu sunt √Æn contextul oferit.)\n",
    "---\n",
    "\n",
    "√éntrebarea utilizatorului este:  \n",
    "{question}\n",
    "\n",
    "Informa»õiile disponibile sunt:  \n",
    "{context}\n",
    "\n",
    "Scrie rƒÉspunsul √Æn limba rom√¢nƒÉ. Acesta trebuie sƒÉ fie clar, politicos »ôi u»ôor de √Æn»õeles.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "### üîπ **rollama3-8b-instruct ‚Äî Prompt 5 Summary**\n",
    "\n",
    "| Metric                | Score | Pass Rate |\n",
    "| --------------------- | ----- | --------- |\n",
    "| Answer Relevancy      | 0.785 | 50%       |\n",
    "| Contextual Recall     | 0.761 | 50%       |\n",
    "| Faithfulness          | 0.488 | 50%       |\n",
    "| Understanding (GEval) | 0.489 | 0%        |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* **Understanding remains low**, with 0% pass rate, indicating that answers were still not consistently clear or accessible to laypeople.\n",
    "* **Answer Relevancy and Contextual Recall are decent**, but they dropped slightly compared to Prompt 4, suggesting the prompt may have pushed the model to elaborate or speculate more.\n",
    "* **Faithfulness improved modestly** (50% pass rate vs. 33% in Prompt 4), but still suffers due to hallucinated legal details or misinterpretation of the context.\n",
    "* Some outputs **added extra legal context** or speculated on procedures (e.g., arrest duration, contract formality), hurting faithfulness and clarity.\n",
    "\n",
    "**Takeaway:**\n",
    "Prompt 5 did not significantly improve model understanding. It introduced a minor boost in faithfulness and kept contextual alignment steady, but clarity and simplicity for non-experts did not improve, possibly due to over-detailed or over-legalistic generation.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **rollama2-7b-instruct ‚Äî Prompt 5 Summary**\n",
    "\n",
    "| Metric                | Score | Pass Rate |\n",
    "| --------------------- | ----- | --------- |\n",
    "| Answer Relevancy      | 0.844 | 66.7%     |\n",
    "| Contextual Recall     | 0.733 | 50%       |\n",
    "| Faithfulness          | 0.620 | 33.3%     |\n",
    "| Understanding (GEval) | 0.485 | 0%        |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "* **Relevancy improved** significantly compared to Prompt 4, indicating that the model responded more directly to questions.\n",
    "* **Understanding still scored poorly**, failing all GEval checks, meaning the output remains too ambiguous, verbose, or poorly structured for a layperson.\n",
    "* **Faithfulness was inconsistent**: one-third of answers failed due to added assumptions, vague exceptions, or unsupported legal claims.\n",
    "* A few responses **misrepresented legal structures** (e.g., age for marriage, contract validity), indicating prompt constraints were insufficient to prevent hallucination.\n",
    "\n",
    "**Takeaway:**\n",
    "Prompt 5 helped Rollama2 become more relevant and aligned with context, but failed to address core issues with user-friendly understanding and hallucination. It may have encouraged verbosity and added legal complexity that confused the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a17c9",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Conclusion\n",
    "\n",
    "After testing five versions of the prompt, we decided to **stick with Prompt v4**, which achieves the most balanced performance in terms of **clarity**, **faithfulness**, and **realistic output quality**‚Äîespecially when used with the `rollama3-8b-instruct` model.\n",
    "\n",
    "### üîπ Why Prompt v4?\n",
    "\n",
    "Compared to earlier prompts, Prompt v4 introduces key improvements:\n",
    "\n",
    "* **Stricter grounding**: The model is explicitly instructed to use *only* the provided context, which reduces hallucinations and off-topic responses.\n",
    "* **Controlled fallback behavior**: The default message ‚ÄúNu am putut genera un rƒÉspuns.‚Äù is used only when the context is clearly insufficient.\n",
    "* **Simplified tone and structure**: Rules are more concise and directive, improving the model's response focus and reducing ambiguity.\n",
    "* **User-friendly phrasing**: Maintains a polite, accessible tone appropriate for a non-expert audience, especially in legal contexts.\n",
    "\n",
    "### üìä Model Performance Recap (Prompt v4)\n",
    "\n",
    "| Metric             | rollama3-8b-instruct | rollama2-7b-instruct | Best Model |\n",
    "| ------------------ | -------------------- | -------------------- | ---------- |\n",
    "| **Relevancy**      | ‚úÖ **0.951** (100%)   | ‚ö†Ô∏è 0.745 (66.7%)     | ‚úÖ 8B       |\n",
    "| **Faithfulness**   | ‚ö†Ô∏è 0.524 (33.3%)     | ‚úÖ **0.727** (66.7%)  | ‚úÖ 7B       |\n",
    "| **Contextual Use** | ‚ûñ 0.733 (50%)        | ‚ûñ 0.722 (50%)        | Tie        |\n",
    "| **Understanding**  | ‚ùå 0.528              | ‚ùå 0.507              | Neither    |\n",
    "\n",
    "> ‚ö†Ô∏è Even though **Understanding (GEval)** did not reach the desired 0.7 threshold, the **0.52 average** for the 8B model is **a solid result**, given that the source material consists of dense legal texts with complex structure. For the intended user-facing task (explaining law in plain Romanian), this is **an acceptable and encouraging performance baseline**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Recommendation\n",
    "\n",
    "We recommend using **`rollama3-8b-instruct` with Prompt v4** for production:\n",
    "\n",
    "* ‚úÖ **Best answer relevancy**: All responses are clearly aligned with user queries.\n",
    "* ‚úÖ **Better grammar and natural phrasing**, more suitable for end-user deployment.\n",
    "* ‚ö†Ô∏è **Faithfulness is lower** than 7B, but acceptable considering the gain in clarity and fluidity.\n",
    "* ‚ö†Ô∏è **Understanding** remains below threshold, but is reasonable given the legal complexity.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
